{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_block(inp):\n",
    "    inp1 = inp\n",
    "    conv = Conv2D(filters=13, kernel_size=3, strides=2, padding='same', use_bias=False, kernel_initializer='he_normal')(inp)\n",
    "    pool = MaxPool2D(2)(inp1)\n",
    "    concat = concatenate([conv, pool])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_bottleneck(inp, filters, dilation_rate=2, downsample=False, dilated=False, asymmetric=False, drop_rate=0.1):\n",
    "    reduce = filters // 4\n",
    "    down = inp\n",
    "    kernel_stride = 1\n",
    "    \n",
    "    #Downsample\n",
    "    if downsample:\n",
    "        kernel_stride = 2\n",
    "        pad_activations = filters - inp.shape.as_list()[-1]\n",
    "        down = MaxPool2D(2)(down)\n",
    "        down = Permute(dims=(1, 3, 2))(down)\n",
    "        down = ZeroPadding2D(padding=((0, 0), (0, pad_activations)))(down)\n",
    "        down = Permute(dims=(1, 3, 2))(down)\n",
    "    \n",
    "    #1*1 Reduce\n",
    "    x = Conv2D(filters=reduce, kernel_size=kernel_stride, strides=kernel_stride, padding='same', use_bias=False, kernel_initializer='he_normal')(inp)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    #Conv\n",
    "    if not dilated and not asymmetric:\n",
    "        x = Conv2D(filters=reduce, kernel_size=kernel_stride, padding='same', kernel_initializer='he_normal')(x)\n",
    "    elif dilated:\n",
    "        x = Conv2D(filters=reduce, kernel_size=kernel_stride, padding='same', dilation_rate=dilation_rate, kernel_initializer='he_normal')(x)\n",
    "    elif asymmetric:\n",
    "        x = Conv2D(filters=reduce, kernel_size=(1,5), padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "        x = Conv2D(filters=reduce, kernel_size=(5,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    #1*1 Expand\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_stride, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = SpatialDropout2D(rate=drop_rate)(x)\n",
    "    \n",
    "    concat = Add()([x, down])\n",
    "    concat = PReLU(shared_axes=[1, 2])(concat)\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_bottleneck(inp, filters, upsample=False):\n",
    "    reduce = filters // 4\n",
    "    up = inp\n",
    "    \n",
    "    #Upsample\n",
    "    if upsample:\n",
    "        up = Conv2D(filters=filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer='he_normal')(up)\n",
    "        up = UpSampling2D(size=2)(up)\n",
    "    \n",
    "    #1*1 Reduce\n",
    "    x = Conv2D(filters=reduce, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer='he_normal')(inp)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    #Conv\n",
    "    if not upsample:\n",
    "        x = Conv2D(filters=reduce, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    else:\n",
    "        x = Conv2DTranspose(filters=reduce, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    #1*1 Expand\n",
    "    x = Conv2D(filters=filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    \n",
    "    concat = Add()([x, up])\n",
    "    concat = PReLU(shared_axes=[1, 2])(concat)\n",
    "    \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENet(inp, nclasses=1):\n",
    "    enc = initial_block(inp)\n",
    "    enc = BatchNormalization(momentum=0.1)(enc)\n",
    "    enc = PReLU(shared_axes=[1, 2])(enc)\n",
    "\n",
    "    #Bottleneck 1.0\n",
    "    enc = encoder_bottleneck(enc, 64, downsample=True, drop_rate=0.001)\n",
    "\n",
    "    enc = encoder_bottleneck(enc, 64, drop_rate=0.001)\n",
    "    enc = encoder_bottleneck(enc, 64, drop_rate=0.001)\n",
    "    enc = encoder_bottleneck(enc, 64, drop_rate=0.001)\n",
    "    enc = encoder_bottleneck(enc, 64, drop_rate=0.001)\n",
    "\n",
    "    #Bottleneck 2.0\n",
    "    enc = encoder_bottleneck(enc, 128, downsample=True)\n",
    "    enc = encoder_bottleneck(enc, 128)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=2, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128, asymmetric=True)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=4, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=8, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128, asymmetric=True)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=16, dilated=True)\n",
    "\n",
    "    #Bottleneck 3.0\n",
    "    enc = encoder_bottleneck(enc, 128)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=2, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128, asymmetric=True)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=4, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=8, dilated=True)\n",
    "    enc = encoder_bottleneck(enc, 128, asymmetric=True)\n",
    "    enc = encoder_bottleneck(enc, 128, dilation_rate=16, dilated=True)\n",
    "\n",
    "    #Bottleneck 4.0\n",
    "    dec = decoder_bottleneck(enc, 64, upsample=True)\n",
    "    dec = decoder_bottleneck(dec, 64)\n",
    "    dec = decoder_bottleneck(dec, 64)\n",
    "\n",
    "    #Bottleneck 5.0\n",
    "    dec = decoder_bottleneck(dec, 16, upsample=True)\n",
    "    dec = decoder_bottleneck(dec, 16)\n",
    "\n",
    "    dec = Conv2DTranspose(filters=nclasses, kernel_size=3, strides=2, padding='same', activation='softmax')(dec)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=dec, name='Enet')\n",
    "    model.save('enet.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(512, 512, 3))\n",
    "enet = ENet(inp, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
